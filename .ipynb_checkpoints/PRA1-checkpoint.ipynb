{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping trail running races 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook scraps the trail running races' data from https://itra.run/races. Environment preparation is managed by the following scripts:\n",
    "- WindowsEnvironment.ps1\n",
    "- MacOSEnvironment.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import whois\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# What environment am I using?\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obrim un navegador i accedim a la plana que volem treballar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using selenium, open firefox window with the ITRA website\n",
    "driver = webdriver.Firefox()\n",
    "driver.get(\"https://itra.run/races\")\n",
    "\n",
    "# Getting current URL source code \n",
    "get_title = driver.title \n",
    "  \n",
    "# Printing the title of this URL \n",
    "print(get_title) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un cop oberta la plana canviem l'idioma a anglès i sel·leccionem les dates d'inici i de fi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Click dropdown menu for language selection\n",
    "driver.find_element_by_xpath(\"/html/body/div[1]/div[1]/nav/div[4]\").click()\n",
    "\n",
    "# Select language EN\n",
    "driver.find_element_by_xpath(\"/html/body/div[1]/div[1]/nav/div[4]/div/div[1]\").click()\n",
    "\n",
    "# Wait for page laod after click\n",
    "time.sleep(5)\n",
    "\n",
    "# elect init date\n",
    "initYear=2021\n",
    "initMonth=1\n",
    "initDay=1\n",
    "\n",
    "# Picker de la data d'inici\n",
    "dpkStartdate = driver.find_element_by_css_selector(\"div.vdp-datepicker.dp1\")\n",
    "dpkStartdate.click()\n",
    "\n",
    "# Picker per mostrar anys\n",
    "spnMonthSelector = driver.find_element_by_css_selector(\".dp1 span.day__month_btn.up\")\n",
    "spnMonthSelector.click()\n",
    "\n",
    "# Picker per mostrar anys\n",
    "spnYearSelector = driver.find_element_by_css_selector(\".dp1 span.month__year_btn.up\")\n",
    "spnYearSelector.click()\n",
    "\n",
    "# Picker per seleccionar any\n",
    "divYears = driver.find_elements_by_css_selector(\".dp1 span.cell.year\")\n",
    "divYears[initYear-2020].click()\n",
    "\n",
    "# Picker per seleccionar mes\n",
    "divMonths = driver.find_elements_by_css_selector(\".dp1 span.cell.month\")\n",
    "divMonths[initMonth-1].click()\n",
    "\n",
    "# Picker per seleccionar dia\n",
    "divDays = driver.find_elements_by_css_selector(\".dp1 span.cell.day\")\n",
    "# Get the days from the previous month in the current mont first week\n",
    "divBlankDays = driver.find_elements_by_css_selector(\".dp1 span.cell.day.blank\")\n",
    "divDays[initDay+len(divBlankDays)-1].click()  \n",
    "\n",
    "# Select end date\n",
    "endYear=2021\n",
    "endMonth=12\n",
    "endDay=31\n",
    "\n",
    "dpkStartdate = driver.find_element_by_css_selector(\"div.vdp-datepicker.dp2\")\n",
    "dpkStartdate.click()\n",
    "\n",
    "spnMonthSelector = driver.find_element_by_css_selector(\".dp2 span.day__month_btn.up\")\n",
    "spnMonthSelector.click()\n",
    "\n",
    "spnYearSelector = driver.find_element_by_css_selector(\".dp2 span.month__year_btn.up\")\n",
    "spnYearSelector.click()\n",
    "\n",
    "divYears = driver.find_elements_by_css_selector(\".dp2 span.cell.year\")\n",
    "divYears[endYear-2020].click()\n",
    "\n",
    "divMonths = driver.find_elements_by_css_selector(\".dp2 span.cell.month\")\n",
    "divMonths[endMonth-1].click()\n",
    "\n",
    "divDays = driver.find_elements_by_css_selector(\".dp2 span.cell.day\")\n",
    "# Get the days from the previous month in the current mont first week\n",
    "divBlankDays = driver.find_elements_by_css_selector(\".dp2 span.cell.day.blank\")\n",
    "divDays[endDay+len(divBlankDays)-1].click()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carreguem totes les curses fins que no n'hi hagi més."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on More Races to get the full list on the screen & Wait for Visibility of Races\n",
    " maxIterations = 10 #-1 for ALL\n",
    "i = 0\n",
    "try:\n",
    "    btnSeeMore = driver.find_element_by_css_selector('button.btn-itra-black[type=\"button\"]')    \n",
    "\n",
    "except:\n",
    "    btnSeeMore = None\n",
    "    print(\"No button\")\n",
    "\n",
    "while btnSeeMore is not None and i < maxIterations:\n",
    "    i = i +1\n",
    "    btnSeeMore.click()\n",
    "    try:\n",
    "        btnSeeMore = driver.find_element_by_css_selector('button.btn-itra-black[type=\"button\"]')    \n",
    "\n",
    "    except:\n",
    "        btnSeeMore = None\n",
    "        print(\"No button\")      \n",
    "    finally:\n",
    "        time.sleep(5)\n",
    "\n",
    "print(\"No more results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ara que ja tenim totes les curses carregades obtenim les dades analitzant el codi HTML amb BeautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting current URL source code \n",
    "get_source = driver.page_source\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping race names with BeautifulSoup\n",
    "soup = BeautifulSoup(get_source, 'html')\n",
    "#print(soup.h5)\n",
    "#soup.find_all('h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Find the race names\n",
    "racesList = re.findall(r'(?<=<h5 data-v-f3c4ac1c=\"\" class=\"itra-green\">)(.*?)(?=</h5>)', get_source)\n",
    "print(len(racesList))\n",
    "print(racesList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the mouse over link pointing to the race site\n",
    "links = [a['href'] for a in soup.find_all('a',\"card ontop\", href=True)]\n",
    "print(len(links))\n",
    "print(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the data for distance, elevation gain and loss\n",
    "myList = re.findall(r'(?<=<span class=\"icon-text-grey icon-bold\">)(.*?)(?=</span>)', get_source)\n",
    "#print(myList)\n",
    "#len(myList)\n",
    "\n",
    "# Find the race distance\n",
    "distancesList = myList[0::3]\n",
    "print(len(distancesList))\n",
    "\n",
    "# Find the race elevation gain\n",
    "gainList = myList[1::3]\n",
    "print(len(gainList))\n",
    "\n",
    "# Find the race elevation loss\n",
    "lossList = myList[2::3]\n",
    "print(len(lossList))\n",
    "\n",
    "# Find the race date\n",
    "datesList = re.findall(r'(?<=<span data-v-f3c4ac1c=\"\" class=\"itra-grey\" style=\"margin-top: 0.2rem; margin-left: 0.2rem; margin-right: 2rem; font-size: 80%;\">)(.*?)(?=</span>)', get_source)\n",
    "#print(datesList)\n",
    "print(len(datesList))\n",
    "\n",
    "# Loop\n",
    "# Visit race page in Itra\n",
    "# Scraping www, place, topology, number of participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of finishers of the race\n",
    "#<span class=\"icon-finisher icon-bold\">370</span>\n",
    "finishersList = re.findall(r'(?<=<span class=\"icon-finisher icon-bold\">)(.*?)(?=</span>)', get_source)\n",
    "print(finishersList)\n",
    "len(finishersList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign data to tuples: # get the list of tuples from two lists and merge them by using zip(). \n",
    "list_of_tuples = list(zip(racesList, links, distancesList, gainList, lossList, datesList)) \n",
    "# Converting lists of tuples into pandas Dataframe. \n",
    "df = pd.DataFrame(list_of_tuples, columns = ['Name', 'Link', 'Distance', 'Gain', 'Loss', 'Date'])\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenim els identificadors únics de les curses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary part of the string\n",
    "sep = 'https://itra.run/race/'\n",
    "id_unic =[item.split(sep, 1)[1] for item in links]\n",
    "\n",
    "id_unic.remove('21867')\n",
    "\n",
    "# Removing single quotes (effectively transforms it to int)\n",
    "id_unic_int=[int(x) for x in id_unic]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ara ataquem les dades de la pàgina específica de cada cursa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraccio de dades de les planes detallades\n",
    "import requests\n",
    "import json\n",
    "\n",
    "#id_unic.remove('21867')\n",
    "\n",
    "# Removing single quotes (effectively transforms it to int)\n",
    "id_unic_int=[int(x) for x in id_unic]\n",
    "\n",
    "\n",
    "# List of json containing datailed info on each race\n",
    "jsonList = []\n",
    "\n",
    "# List of json containing datailed info on each race\n",
    "cursesList = []\n",
    "\n",
    "# Parameter year of interest\n",
    "year = 2021\n",
    "\n",
    "# Loop over the urls to obtain details in json\n",
    "for item in id_unic_int:\n",
    "    \n",
    "    # url and request\n",
    "    url = \"https://itra.run/evt/racewdetails/\"\n",
    "    final_url = f'{url}{item}/{year}'\n",
    "    r = requests.get(final_url)\n",
    "   \n",
    "    # Add to list of json races\n",
    "    cursa=r.json()[0]\n",
    "    jsonList.append(cursa)\n",
    "    \n",
    "    # Add to dataframe of races    \n",
    "    df_cursa = pd.DataFrame([cursa])\n",
    "    print(df_cursa)\n",
    "    cursesList.append(df_cursa)\n",
    "\n",
    "# Dataframe detailed race information\n",
    "df_detailed = pd.concat(cursesList)\n",
    "df_detailed=df_detailed.reset_index(drop=True)\n",
    "\n",
    "# Concatenate df & df_detailed by column\n",
    "df_curses_2021 = pd.concat([df, df_detailed], axis=1)\n",
    "df_curses_2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
