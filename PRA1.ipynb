{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping trail running races 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook scraps the trail running races' data from https://itra.run/races. Environment preparation is managed by the following scripts:\n",
    "- WindowsEnvironment.ps1\n",
    "- MacOSEnvironment.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "15:04:19: Log started\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "# Logging format\n",
    "format = \"%(asctime)s: %(message)s\"\n",
    "#logging.basicConfig(filename='example.log', format=format, level=logging.INFO,datefmt=\"%H:%M:%S\")\n",
    "logging.basicConfig(format=format, level=logging.INFO,datefmt=\"%H:%M:%S\")\n",
    "logging.info(\"Log started\")\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import concurrent.futures\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import whois\n",
    "import sys\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "# Logging format\n",
    "format = \"%(asctime)s: %(message)s\"\n",
    "logging.basicConfig(format=format, level=logging.DEBUG,\n",
    "                    datefmt=\"%H:%M:%S\")\n"
   ]
  },
  {
   "source": [
    "Per tal de ser més eficients, crarem 3 instàncies d'exploradors que facin la mateixa feina però amb rangs de dates diferentes. Al final unirem els resultats."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "15:11:30: splitTimePeriod 2021-01-01 00:00:00 / 2021-02-05 00:00:00 period in 1 subperiods: starting\n",
      "15:11:30: splitTimePeriod 2021-01-01 00:00:00 / 2021-02-05 00:00:00 period in 1 subperiods: total duration in days: 35.0\n",
      "15:11:30: splitTimePeriod 2021-01-01 00:00:00 / 2021-02-05 00:00:00 period in 1 subperiods: subperiod duration in days: 35.0\n",
      "15:11:30: Thread 0 for [datetime.datetime(2021, 1, 1, 0, 0), datetime.datetime(2021, 2, 5, 0, 0)] period: starting getRacesSeq\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda\\envs\\PRA1001\\lib\\logging\\__init__.py\", line 1025, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\Anaconda\\envs\\PRA1001\\lib\\logging\\__init__.py\", line 869, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\Anaconda\\envs\\PRA1001\\lib\\logging\\__init__.py\", line 608, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\Anaconda\\envs\\PRA1001\\lib\\logging\\__init__.py\", line 369, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not enough arguments for format string\n",
      "Call stack:\n",
      "  File \"C:\\Anaconda\\envs\\PRA1001\\lib\\threading.py\", line 890, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Anaconda\\envs\\PRA1001\\lib\\threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Anaconda\\envs\\PRA1001\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Anaconda\\envs\\PRA1001\\lib\\concurrent\\futures\\thread.py\", line 80, in _worker\n",
      "    work_item.run()\n",
      "  File \"C:\\Anaconda\\envs\\PRA1001\\lib\\concurrent\\futures\\thread.py\", line 57, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"<ipython-input-7-37608bc02426>\", line 112, in getRacesSeq\n",
      "    logging.info(\"Thread %s for %s period: Period duration is %s days\", n, durationDays)\n",
      "Message: 'Thread %s for %s period: Period duration is %s days'\n",
      "Arguments: (0, 35)\n",
      "15:11:30: splitTimePeriod 2021-01-01 00:00:00 / 2021-02-05 00:00:00 period in 1 subperiods: starting\n",
      "15:11:30: splitTimePeriod 2021-01-01 00:00:00 / 2021-02-05 00:00:00 period in 1 subperiods: total duration in days: 35.0\n",
      "15:11:30: splitTimePeriod 2021-01-01 00:00:00 / 2021-02-05 00:00:00 period in 1 subperiods: subperiod duration in days: 35.0\n",
      "15:11:30: Thread 0 for [datetime.datetime(2021, 1, 1, 0, 0), datetime.datetime(2021, 2, 5, 0, 0)] period: Processing period\n",
      "15:11:30: Thread 0 for [datetime.datetime(2021, 1, 1, 0, 0), datetime.datetime(2021, 2, 5, 0, 0)] period: starting getRaces\n",
      "15:11:55: Thread [datetime.datetime(2021, 1, 1, 0, 0), datetime.datetime(2021, 2, 5, 0, 0)] for 0 period: 0 iteration\n",
      "15:11:56: Thread [datetime.datetime(2021, 1, 1, 0, 0), datetime.datetime(2021, 2, 5, 0, 0)] for 0 period: 1 iteration\n",
      "15:12:01: Thread [datetime.datetime(2021, 1, 1, 0, 0), datetime.datetime(2021, 2, 5, 0, 0)] for 0 period: 2 iteration\n",
      "15:12:07: Thread [datetime.datetime(2021, 1, 1, 0, 0), datetime.datetime(2021, 2, 5, 0, 0)] for 0 period: 3 iteration\n",
      "15:12:12: Thread [datetime.datetime(2021, 1, 1, 0, 0), datetime.datetime(2021, 2, 5, 0, 0)] for 0 period: 4 iteration\n",
      "15:12:18: Thread [datetime.datetime(2021, 1, 1, 0, 0), datetime.datetime(2021, 2, 5, 0, 0)] for 0 period: 5 iteration\n",
      "15:12:23: Thread [datetime.datetime(2021, 1, 1, 0, 0), datetime.datetime(2021, 2, 5, 0, 0)] for 0 period: 6 iteration\n",
      "15:12:28: Thread [datetime.datetime(2021, 1, 1, 0, 0), datetime.datetime(2021, 2, 5, 0, 0)] for 0 period: 7 iteration\n",
      "15:12:33: Thread [datetime.datetime(2021, 1, 1, 0, 0), datetime.datetime(2021, 2, 5, 0, 0)] for 0 period: 8 iteration\n",
      "15:12:39: Thread [datetime.datetime(2021, 1, 1, 0, 0), datetime.datetime(2021, 2, 5, 0, 0)] for 0 period: 9 iteration\n",
      "15:12:44: Thread [datetime.datetime(2021, 1, 1, 0, 0), datetime.datetime(2021, 2, 5, 0, 0)] for 0 period: 10 iteration\n",
      "15:12:49: Thread [datetime.datetime(2021, 1, 1, 0, 0), datetime.datetime(2021, 2, 5, 0, 0)] for 0 period: 11 iteration\n",
      "15:12:55: Thread [datetime.datetime(2021, 1, 1, 0, 0), datetime.datetime(2021, 2, 5, 0, 0)] for 0 period: 12 iteration\n",
      "15:13:00: Thread [datetime.datetime(2021, 1, 1, 0, 0), datetime.datetime(2021, 2, 5, 0, 0)] for 0 period: 13 iteration\n",
      "15:13:05: Thread [datetime.datetime(2021, 1, 1, 0, 0), datetime.datetime(2021, 2, 5, 0, 0)] for 0 period: 14 iteration\n",
      "15:13:10: Thread [datetime.datetime(2021, 1, 1, 0, 0), datetime.datetime(2021, 2, 5, 0, 0)] for 0 period: 15 iteration\n",
      "15:13:16: Thread [datetime.datetime(2021, 1, 1, 0, 0), datetime.datetime(2021, 2, 5, 0, 0)] for 0 period: 16 iteration\n",
      "15:13:21: Thread [datetime.datetime(2021, 1, 1, 0, 0), datetime.datetime(2021, 2, 5, 0, 0)] for 0 period: 17 iteration\n",
      "15:13:27: Thread [datetime.datetime(2021, 1, 1, 0, 0), datetime.datetime(2021, 2, 5, 0, 0)] for 0 period: 18 iteration\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-37608bc02426>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[1;31m# Parallel execution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mThreadPoolExecutor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthreads\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m     \u001b[0mresultPeriods\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetRacesSeq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthreads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mperiods\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;31m# Concatene all results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\PRA1001\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult_iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    596\u001b[0m                     \u001b[1;31m# Careful not to keep a reference to the popped future\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m                         \u001b[1;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m                         \u001b[1;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\PRA1001\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    428\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\PRA1001\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def splitTimePeriod(n, start, end):\n",
    "    \"\"\"\n",
    "    splitTimePeriod gets an array of dates [n,2] with the period splatted in n subperiods\n",
    "\n",
    "    :param n: number of subperiods\n",
    "    :param start: Start date \n",
    "    :param end: End date \n",
    "    :return: returns a [n,2] matrix with the subperiods dates\n",
    "    \"\"\"     \n",
    "    logging.info(\"splitTimePeriod %s / %s period in %s subperiods: starting\", start, end, n)\n",
    "\n",
    "    duration = end - start\n",
    "\n",
    "    durationDays = duration.total_seconds() / 60 / 60 / 24\n",
    "    logging.info(\"splitTimePeriod %s / %s period in %s subperiods: total duration in days: %s\", start, end, n, durationDays)\n",
    "\n",
    "    subperiodDuration = durationDays / n\n",
    "    logging.info(\"splitTimePeriod %s / %s period in %s subperiods: subperiod duration in days: %s\", start, end, n, subperiodDuration)\n",
    "\n",
    "    result = []\n",
    "    \n",
    "    if subperiodDuration < 2:\n",
    "        # Too small period return only one array\n",
    "        result = [[start,end]]\n",
    "    else:\n",
    "        # Split the period\n",
    "        init = start\n",
    "        \n",
    "        # Remove decimals\n",
    "        periodDays = int(subperiodDuration)\n",
    "\n",
    "        for x in range(n-1):\n",
    "            result.append([init,init+timedelta(periodDays-1)])\n",
    "            init = init+timedelta(periodDays)\n",
    "\n",
    "        #Last subperiod\n",
    "        result.append([end+timedelta(-periodDays),end])\n",
    "    \n",
    "    return result\n",
    "    \n",
    "def getData(n, htmlSource):\n",
    "    \"\"\"\n",
    "    getData gets the races from ITRA in the given period time\n",
    "\n",
    "    :param htmlSource: Source HTML for the apge \n",
    "    :return: data\n",
    "    \"\"\"\n",
    "    logging.info(\"Thread %s: Getting Data\", n) \n",
    "    \n",
    "    # Scraping race names with BeautifulSoup\n",
    "    soup = BeautifulSoup(htmlSource, 'html')\n",
    "    logging.info(\"Thread %s: html extracted\", n) \n",
    "    \n",
    "    # Find the race names\n",
    "    racesList = re.findall(r'(?<=<h5 data-v-f3c4ac1c=\"\" class=\"itra-green\">)(.*?)(?=</h5>)', htmlSource)\n",
    "    logging.info(\"Thread %s: Number of races %s\",n,len(racesList))\n",
    "    #print(racesList)\n",
    "\n",
    "    # Find the mouse over link pointing to the race site\n",
    "    links = [a['href'] for a in soup.find_all('a',\"card ontop\", href=True)]\n",
    "    logging.info(\"Thread %s: Number of links %s\",n,len(links))\n",
    "\n",
    "    # Scraping the data for distance, elevation gain and loss\n",
    "    myList = re.findall(r'(?<=<span class=\"icon-text-grey icon-bold\">)(.*?)(?=</span>)', htmlSource)\n",
    "    logging.info(\"Thread %s: Number of measures %s\",n,len(myList))\n",
    "\n",
    "    # Find the race distance\n",
    "    distancesList = myList[0::3]\n",
    "    \n",
    "    # Find the race elevation gain\n",
    "    gainList = myList[1::3]\n",
    "    \n",
    "    # Find the race elevation loss\n",
    "    lossList = myList[2::3]\n",
    "    \n",
    "    # Find the race date\n",
    "    datesList = re.findall(r'(?<=<span data-v-f3c4ac1c=\"\" class=\"itra-grey\" style=\"margin-top: 0.2rem; margin-left: 0.2rem; margin-right: 2rem; font-size: 80%;\">)(.*?)(?=</span>)', htmlSource)\n",
    "    #print(datesList)\n",
    "    logging.info(\"Thread %s: Number of races %s\",n,len(datesList))\n",
    "\n",
    "    # Loop\n",
    "    # Visit race page in Itra\n",
    "    # Scraping www, place, topology, number of participants\n",
    "\n",
    "    # Find the number of finishers of the race\n",
    "    #<span class=\"icon-finisher icon-bold\">370</span>\n",
    "    finishersList = re.findall(r'(?<=<span class=\"icon-finisher icon-bold\">)(.*?)(?=</span>)', htmlSource)\n",
    "    logging.info(\"Thread %s: Number of finishers %s\",n,len(finishersList))\n",
    "\n",
    "    # Assign data to tuples: # get the list of tuples from two lists and merge them by using zip(). \n",
    "    list_of_tuples = list(zip(racesList, links, distancesList, gainList, lossList, datesList)) \n",
    "    # Converting lists of tuples into pandas Dataframe. \n",
    "    df = pd.DataFrame(list_of_tuples, columns = ['Name', 'Link', 'Distance', 'Gain', 'Loss', 'Date'])\n",
    "    logging.info(\"Thread %s: Get Data terminated\", n) \n",
    "    return df\n",
    "\n",
    "def getRacesSeq(n, period, maxDuration=30):\n",
    "    \"\"\"\n",
    "    getRacesSeq gets the races from ITRA in the given period time. Opens a new browser session for each maxDuration days to avoid issues with the borwser when too much races needs to bre retrieved.\n",
    "\n",
    "    :param n: Thread context execution\n",
    "    :param period: Start and End date \n",
    "    :param maxDuration: Maximum days to query to the browser\n",
    "    :return: All races with high level data for the given period\n",
    "    \"\"\" \n",
    "    logging.info(\"Thread %s for %s period: starting getRacesSeq\", n, period)\n",
    "\n",
    "    # Get the number of subperiods\n",
    "    duration = period[1] - period[0]\n",
    "    durationDays = int(duration.total_seconds() / 60 / 60 / 24)\n",
    "    \n",
    "    logging.info(\"Thread %s for %s period: Period duration is %s days\", n, durationDays)\n",
    "    subperiodsSeq = splitTimePeriod(int(durationDays/maxDuration), period[0], period[1])\n",
    "    \n",
    "    i = 0\n",
    "    result = []\n",
    "\n",
    "    while i < len(subperiodsSeq):\n",
    "        logging.info(\"Thread %s for %s period: Processing period\", n, subperiodsSeq[i])\n",
    "        resultAux = getRaces(n,subperiodsSeq[i])\n",
    "        logging.info(\"Thread %s for %s period: Processed period with %s races\", n, subperiodsSeq[i], len(resultAux))\n",
    "        result.append(resultAux)\n",
    "        i = i + 1\n",
    "    result  = pd.concat(result)\n",
    "    logging.info(\"Thread %s for %s period: terminated getRacesSeq with %s records\", n, period, len(result))\n",
    "\n",
    "def getRaces(n, period):\n",
    "    \"\"\"\n",
    "    getRaces gets the races from ITRA in the given period time\n",
    "\n",
    "    :param n: Thread context execution\n",
    "    :param period: Start and End date \n",
    "    :return: All races with high level data for the given period\n",
    "    \"\"\" \n",
    "    logging.info(\"Thread %s for %s period: starting getRaces\", n, period)\n",
    "    \n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Using selenium, open firefox window with the ITRA website\n",
    "    driver = webdriver.Firefox()\n",
    "    driver.get(\"https://itra.run/races\")\n",
    "\n",
    "    # Getting current URL source code \n",
    "    get_title = driver.title \n",
    "\n",
    "    # Click dropdown menu for language selection\n",
    "    driver.find_element_by_xpath(\"/html/body/div[1]/div[1]/nav/div[4]\").click()\n",
    "\n",
    "    # Select language EN\n",
    "    driver.find_element_by_xpath(\"/html/body/div[1]/div[1]/nav/div[4]/div/div[1]\").click()\n",
    "\n",
    "    # Wait for page load after click\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Select init date\n",
    "    initYear=period[0].year\n",
    "    initMonth=period[0].month\n",
    "    initDay=period[0].day\n",
    "\n",
    "    # Picker de la data d'inici\n",
    "    dpkStartdate = driver.find_element_by_css_selector(\"div.vdp-datepicker.dp1\")\n",
    "    dpkStartdate.click()\n",
    "\n",
    "    # Picker per mostrar anys\n",
    "    spnMonthSelector = driver.find_element_by_css_selector(\".dp1 span.day__month_btn.up\")\n",
    "    spnMonthSelector.click()\n",
    "\n",
    "    # Picker per mostrar anys\n",
    "    spnYearSelector = driver.find_element_by_css_selector(\".dp1 span.month__year_btn.up\")\n",
    "    spnYearSelector.click()\n",
    "\n",
    "    # Picker per seleccionar any\n",
    "    divYears = driver.find_elements_by_css_selector(\".dp1 span.cell.year\")\n",
    "    divYears[initYear-2020].click()\n",
    "\n",
    "    # Picker per seleccionar mes\n",
    "    divMonths = driver.find_elements_by_css_selector(\".dp1 span.cell.month\")\n",
    "    divMonths[initMonth-1].click()\n",
    "\n",
    "    # Picker per seleccionar dia\n",
    "    divDays = driver.find_elements_by_css_selector(\".dp1 span.cell.day\")\n",
    "    # Get the days from the previous month in the current mont first week\n",
    "    divBlankDays = driver.find_elements_by_css_selector(\".dp1 span.cell.day.blank\")\n",
    "    divDays[initDay+len(divBlankDays)-1].click()  \n",
    "\n",
    "    # Select end date\n",
    "    endYear=period[1].year\n",
    "    endMonth=period[1].month\n",
    "    endDay=period[1].day\n",
    "\n",
    "    # Picker de la data d'inici\n",
    "    dpkStartdate = driver.find_element_by_css_selector(\"div.vdp-datepicker.dp2\")\n",
    "    dpkStartdate.click()\n",
    "\n",
    "    # Picker per mostrar anys\n",
    "    spnMonthSelector = driver.find_element_by_css_selector(\".dp2 span.day__month_btn.up\")\n",
    "    spnMonthSelector.click()\n",
    "\n",
    "    # Picker per mostrar anys\n",
    "    spnYearSelector = driver.find_element_by_css_selector(\".dp2 span.month__year_btn.up\")\n",
    "    spnYearSelector.click()\n",
    "\n",
    "    # Picker per seleccionar any\n",
    "    divYears = driver.find_elements_by_css_selector(\".dp2 span.cell.year\")\n",
    "    divYears[endYear-2020].click()\n",
    "\n",
    "    # Picker per seleccionar mes\n",
    "    divMonths = driver.find_elements_by_css_selector(\".dp2 span.cell.month\")\n",
    "    divMonths[endMonth-1].click()\n",
    "\n",
    "    # Picker per seleccionar dia\n",
    "    divDays = driver.find_elements_by_css_selector(\".dp2 span.cell.day\")\n",
    "    # Get the days from the previous month in the current mont first week\n",
    "    divBlankDays = driver.find_elements_by_css_selector(\".dp2 span.cell.day.blank\")\n",
    "    divDays[endDay+len(divBlankDays)-1].click()  \n",
    "\n",
    "    # Click on More Races to get the full list on the screen & Wait for Visibility of Races\n",
    "    maxIterations = -1 #-1 for ALL\n",
    "    i = 0\n",
    "    try:\n",
    "        logging.info(\"Thread %s for %s period: %s iteration\", period, n, i)\n",
    "        btnSeeMore = driver.find_element_by_css_selector('button.btn-itra-black[type=\"button\"]')    \n",
    "\n",
    "    except:\n",
    "        btnSeeMore = None\n",
    "        logging.info(\"Thread %s for %s period: No more races\", period, n)\n",
    "\n",
    "    while btnSeeMore is not None and i != maxIterations:\n",
    "        i = i+1\n",
    "        btnSeeMore.click()\n",
    "\n",
    "        try:\n",
    "            logging.info(\"Thread %s for %s period: %s iteration\", period, n, i)\n",
    "            btnSeeMore = driver.find_element_by_css_selector('button.btn-itra-black[type=\"button\"]') \n",
    "            \n",
    "        except:            \n",
    "            btnSeeMore = None\n",
    "            logging.info(\"Thread %s for %s period: No more races\", period, n)\n",
    "            break\n",
    "\n",
    "        finally:\n",
    "            time.sleep(5)\n",
    "    \n",
    "    # Obtnim les dades amb BaeatifulSoup \n",
    "    resultPeriod = getData(n, driver.page_source)\n",
    "    logging.info(\"Thread %s for %s period: Data frame returned with %s records\", period, n, len(resultPeriod))\n",
    "    #driver.quit()\n",
    "    return resultPeriod\n",
    "\n",
    "# Period definition\n",
    "startDate = datetime.datetime(2021, 1, 1, 0, 0, 0)\n",
    "endDate = datetime.datetime(2021, 2, 5, 0, 0, 0)\n",
    "\n",
    "# Number of threads\n",
    "threads = 1\n",
    "\n",
    "# Get periods\n",
    "periods = splitTimePeriod(threads, startDate, endDate)\n",
    "\n",
    "# Parallel execution\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=threads) as executor:\n",
    "    resultPeriods = list(executor.map(getRacesSeq, range(threads),periods))\n",
    "\n",
    "# Concatene all results\n",
    "resultFullPeriod = pd.concat(resultPeriods)\n",
    "logging.info(\"Races for period %s to %s is %s\", startDate, endDate, len(resultFullPeriod))\n",
    "print(resultFullPeriod)\n"
   ]
  },
  {
   "source": [
    "Un cop oberta la plana canviem l'idioma a anglès i sel·leccionem les dates d'inici i de fi."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "result2 = pd.concat(result)\n",
    "len(result2)\n",
    "\n"
   ]
  },
  {
   "source": [
    "Carreguem totes les curses fins que no n'hi hagi més."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "Ara que ja tenim totes les curses carregades obtenim les dades analitzant el codi HTML amb BeautifulSoup."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting current URL source code \n",
    "get_source = driver.page_source\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping race names with BeautifulSoup\n",
    "soup = BeautifulSoup(get_source, 'html')\n",
    "#print(soup.h5)\n",
    "#soup.find_all('h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Find the race names\n",
    "racesList = re.findall(r'(?<=<h5 data-v-f3c4ac1c=\"\" class=\"itra-green\">)(.*?)(?=</h5>)', get_source)\n",
    "print(len(racesList))\n",
    "print(racesList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the mouse over link pointing to the race site\n",
    "links = [a['href'] for a in soup.find_all('a',\"card ontop\", href=True)]\n",
    "print(len(links))\n",
    "print(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the data for distance, elevation gain and loss\n",
    "myList = re.findall(r'(?<=<span class=\"icon-text-grey icon-bold\">)(.*?)(?=</span>)', get_source)\n",
    "#print(myList)\n",
    "#len(myList)\n",
    "\n",
    "# Find the race distance\n",
    "distancesList = myList[0::3]\n",
    "print(len(distancesList))\n",
    "\n",
    "# Find the race elevation gain\n",
    "gainList = myList[1::3]\n",
    "print(len(gainList))\n",
    "\n",
    "# Find the race elevation loss\n",
    "lossList = myList[2::3]\n",
    "print(len(lossList))\n",
    "\n",
    "# Find the race date\n",
    "datesList = re.findall(r'(?<=<span data-v-f3c4ac1c=\"\" class=\"itra-grey\" style=\"margin-top: 0.2rem; margin-left: 0.2rem; margin-right: 2rem; font-size: 80%;\">)(.*?)(?=</span>)', get_source)\n",
    "#print(datesList)\n",
    "print(len(datesList))\n",
    "\n",
    "# Loop\n",
    "# Visit race page in Itra\n",
    "# Scraping www, place, topology, number of participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of finishers of the race\n",
    "# TODO: Els fem servir?\n",
    "#<span class=\"icon-finisher icon-bold\">370</span>\n",
    "finishersList = re.findall(r'(?<=<span class=\"icon-finisher icon-bold\">)(.*?)(?=</span>)', get_source)\n",
    "print(finishersList)\n",
    "len(finishersList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign data to tuples: # get the list of tuples from two lists and merge them by using zip(). \n",
    "list_of_tuples = list(zip(racesList, links, distancesList, gainList, lossList, datesList)) \n",
    "# Converting lists of tuples into pandas Dataframe. \n",
    "df = pd.DataFrame(list_of_tuples, columns = ['Name', 'Link', 'Distance', 'Gain', 'Loss', 'Date'])\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAL DESAR LES DADES EN UN FORMAT ADIENT: JSON? CSV directament ja que l'enunciat de la PRACTICA requereix CSV\n",
    "\n",
    "# Convert results to json and save the file\n",
    "with open('result.json', 'w') as fp:\n",
    "    json.dump(sample, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(iList)\n",
    "print(iiList)\n",
    "print(iiList_of_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ara ataquem les dades de la pàgina específica de cada cursa\n",
    "\n",
    "\n",
    "# List with race websites\n",
    "websitesList = []\n",
    "\n",
    "# List with race place and country\n",
    "locationList = []\n",
    "\n",
    "# List containing the table for each website (as a list)\n",
    "tableList = []\n",
    "\n",
    "\n",
    "#slicedLinks = links[:5]\n",
    "\n",
    "for i in tqdm(links):\n",
    "    print(i)\n",
    "    # Using selenium, open firefox window with the ITRA website\n",
    "    driver2 = webdriver.Firefox()\n",
    "    #driver2.get(\"https://itra.run/race/13893\")\n",
    "    driver2.get(i)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        time.sleep(3)   \n",
    "\n",
    "        # Click dropdown menu for language selection\n",
    "        driver2.find_element_by_xpath(\"/html/body/div[1]/div[1]/nav/div[4]\").click()\n",
    "\n",
    "        # Select language EN\n",
    "        driver2.find_element_by_xpath(\"/html/body/div[1]/div[1]/nav/div[4]/div/div[1]\").click()\n",
    "\n",
    "        time.sleep(15)\n",
    "        \n",
    "        # if link is broken, go back\n",
    "    except TimeoutException:\n",
    "        driver2.back()\n",
    "        print(\"Time out exception.\")\n",
    "        # continue so we can return to beginning of loop\n",
    "        continue\n",
    "\n",
    "    # if you reach this point, the link is valid, and you can 'do stuff' on the page\n",
    "    \n",
    "    # Getting current URL source code \n",
    "    get_source2 = driver2.page_source\n",
    "    time.sleep(2)   \n",
    "    driver2.close()\n",
    "\n",
    "    # Scraping race names with BeautifulSoup\n",
    "    soup2 = BeautifulSoup(get_source2, 'html')\n",
    "\n",
    "    # List containing the race website (when available) and \"facebook\", \"twitter\" and other info\n",
    "    hrefList = [a['href'] for a in soup2.find_all('a', {'rel': \"ugc\"}, href=True)]\n",
    "\n",
    "    # Remove the links that contain \"facebook\" or \"twitter\" or \"@\"\n",
    "    hrefList[:] = [x for x in hrefList if \"facebook\" not in x]\n",
    "    hrefList[:] = [x for x in hrefList if \"twitter\" not in x]\n",
    "    hrefList[:] = [x for x in hrefList if \"@\" not in x]\n",
    "\n",
    "    print(len(hrefList))\n",
    "    print(hrefList) \n",
    "    websitesList.append(hrefList)\n",
    "    \n",
    "    # Srape the table with additional data: data labels (first) and content\n",
    "    labelsList  = re.findall(r'(?<=<div class=\"colinforace1\">)(.*?)(?=</div>)', get_source2)\n",
    "    contentList = re.findall(r'(?<=<div class=\"colinforace2 mbb\">)(.*?)(?=</div>)', get_source2)\n",
    "\n",
    "    labels_content_list_of_tuples = list(zip(labelsList[:13], contentList[:13])) \n",
    "    print(labels_content_list_of_tuples)\n",
    "    tableList.append(labels_content_list_of_tuples)\n",
    "    \n",
    "    # Scrape the location\n",
    "    location = soup2.find('p').getText()\n",
    "    print(location)\n",
    "    locationList.append(location)\n",
    "    \n",
    "    # Check scraped data is saved in a manner that can be directly matched\n",
    "    print(len(websitesList))\n",
    "    print(len(locationList))\n",
    "    print(len(tableList))\n",
    "    \n",
    "print(websitesList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}