{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping trail running races 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook scraps the trail running races' data from https://itra.run/races. Environment preparation is managed by the following scripts:\n",
    "- WindowsEnvironment.ps1\n",
    "- MacOSEnvironment.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "# Logging format\n",
    "format = \"%(asctime)s: %(message)s\"\n",
    "logging.basicConfig(filename='PRA1.log', format=format, level=logging.INFO,datefmt=\"%H:%M:%S\")\n",
    "#logging.basicConfig(format=format, level=logging.INFO,datefmt=\"%H:%M:%S\")\n",
    "logging.info(\"Log started\")\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import concurrent.futures\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import whois\n",
    "import sys\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from datetime import timedelta\n",
    "import requests\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per tal de ser més eficients, crarem diferents instàncies d'exploradors que facin la mateixa feina però amb rangs de dates diferents. Primer definim una funció que permet partir un període de temps en subperiodes."
   ]
  },
  {
   "source": [
    "def splitTimePeriod(n, start, end):\n",
    "    \"\"\"\n",
    "    splitTimePeriod gets an array of dates [n,2] with the period splatted in n subperiods\n",
    "\n",
    "    :param n: number of subperiods\n",
    "    :param start: Start date \n",
    "    :param end: End date \n",
    "    :return: returns a [n,2] matrix with the subperiods dates\n",
    "    \"\"\"     \n",
    "    logging.info(\"splitTimePeriod %s / %s period in %s subperiods: starting\", start, end, n)\n",
    "\n",
    "    duration = end - start\n",
    "\n",
    "    durationDays = duration.total_seconds() / 60 / 60 / 24\n",
    "    logging.info(\"splitTimePeriod %s / %s period in %s subperiods: total duration in days: %s\", start, end, n, durationDays)\n",
    "\n",
    "    subperiodDuration = 1\n",
    "    \n",
    "    if n != 0:\n",
    "        subperiodDuration = durationDays / n\n",
    "\n",
    "    logging.info(\"splitTimePeriod %s / %s period in %s subperiods: subperiod duration in days: %s\", start, end, n, subperiodDuration)\n",
    "\n",
    "    result = []\n",
    "    \n",
    "    if subperiodDuration < 2:\n",
    "        # Too small period return only one array\n",
    "        result = [[start,end]]\n",
    "    else:\n",
    "        # Split the period\n",
    "        init = start\n",
    "        \n",
    "        # Remove decimals\n",
    "        periodDays = int(subperiodDuration)\n",
    "\n",
    "        for x in range(n-1):\n",
    "            result.append([init,init+timedelta(periodDays-1)])\n",
    "            init = init+timedelta(periodDays)\n",
    "\n",
    "        #Last subperiod\n",
    "        result.append([init,end])\n",
    "    \n",
    "    return result    "
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "Definim també una funció per a obtenir les dades que ens interessen amb la llibreria BeautifulSoup."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "def getData(n, htmlSource):\n",
    "    \"\"\"\n",
    "    getData gets the races from ITRA in the given period time\n",
    "\n",
    "    :param htmlSource: Source HTML for the apge \n",
    "    :return: data\n",
    "    \"\"\"\n",
    "    logging.info(\"Thread %s: Getting Data\", n) \n",
    "    \n",
    "    # Scraping race names with BeautifulSoup\n",
    "    soup = BeautifulSoup(htmlSource, 'html')\n",
    "    logging.info(\"Thread %s: html extracted\", n) \n",
    "    \n",
    "    # Find the race names\n",
    "    racesList = re.findall(r'(?<=<h5 data-v-f3c4ac1c=\"\" class=\"itra-green\">)(.*?)(?=</h5>)', htmlSource)\n",
    "    logging.info(\"Thread %s: Number of races %s\",n,len(racesList))\n",
    "    #print(racesList)\n",
    "\n",
    "    # Find the mouse over link pointing to the race site\n",
    "    links = [a['href'] for a in soup.find_all('a',\"card ontop\", href=True)]\n",
    "    logging.info(\"Thread %s: Number of links %s\",n,len(links))\n",
    "\n",
    "    # Scraping the data for distance, elevation gain and loss\n",
    "    myList = re.findall(r'(?<=<span class=\"icon-text-grey icon-bold\">)(.*?)(?=</span>)', htmlSource)\n",
    "    logging.info(\"Thread %s: Number of measures %s\",n,len(myList))\n",
    "\n",
    "    # Find the race distance\n",
    "    distancesList = myList[0::3]\n",
    "    \n",
    "    # Find the race elevation gain\n",
    "    gainList = myList[1::3]\n",
    "    \n",
    "    # Find the race elevation loss\n",
    "    lossList = myList[2::3]\n",
    "    \n",
    "    # Find the race date\n",
    "    datesList = re.findall(r'(?<=<span data-v-f3c4ac1c=\"\" class=\"itra-grey\" style=\"margin-top: 0.2rem; margin-left: 0.2rem; margin-right: 2rem; font-size: 80%;\">)(.*?)(?=</span>)', htmlSource)\n",
    "    #print(datesList)\n",
    "    logging.info(\"Thread %s: Number of races %s\",n,len(datesList))\n",
    "\n",
    "    # Assign data to tuples: # get the list of tuples from two lists and merge them by using zip(). \n",
    "    list_of_tuples = list(zip(racesList, links, distancesList, gainList, lossList, datesList)) \n",
    "    # Converting lists of tuples into pandas Dataframe. \n",
    "    df = pd.DataFrame(list_of_tuples, columns = ['Name', 'Link', 'Distance', 'Gain', 'Loss', 'Date'])\n",
    "    logging.info(\"Thread %s: Get Data terminated\", n) \n",
    "    return df"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ara definim una nova funció que obtingui amb selenium el codi font de la plana web de curses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRaces(n, period):\n",
    "    \"\"\"\n",
    "    getRaces gets the races from ITRA in the given period time\n",
    "\n",
    "    :param n: Thread context execution\n",
    "    :param period: Start and End date \n",
    "    :return: All races with high level data for the given period\n",
    "    \"\"\" \n",
    "    logging.info(\"Thread %s for %s period: starting getRaces\", n, period)\n",
    "    \n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Using selenium, open firefox window with the ITRA website\n",
    "    driver = webdriver.Firefox()\n",
    "    driver.get(\"https://itra.run/races\")\n",
    "\n",
    "    # Getting current URL source code \n",
    "    get_title = driver.title \n",
    "\n",
    "    # Click dropdown menu for language selection\n",
    "    driver.find_element_by_xpath(\"/html/body/div[1]/div[1]/nav/div[4]\").click()\n",
    "\n",
    "    # Select language EN\n",
    "    driver.find_element_by_xpath(\"/html/body/div[1]/div[1]/nav/div[4]/div/div[1]\").click()\n",
    "\n",
    "    # Wait for page load after click\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Select init date\n",
    "    initYear=period[0].year\n",
    "    initMonth=period[0].month\n",
    "    initDay=period[0].day\n",
    "\n",
    "    # Picker de la data d'inici\n",
    "    dpkStartdate = driver.find_element_by_css_selector(\"div.vdp-datepicker.dp1\")\n",
    "    dpkStartdate.click()\n",
    "\n",
    "    # Picker per mostrar anys\n",
    "    spnMonthSelector = driver.find_element_by_css_selector(\".dp1 span.day__month_btn.up\")\n",
    "    spnMonthSelector.click()\n",
    "\n",
    "    # Picker per mostrar anys\n",
    "    spnYearSelector = driver.find_element_by_css_selector(\".dp1 span.month__year_btn.up\")\n",
    "    spnYearSelector.click()\n",
    "\n",
    "    # Picker per seleccionar any\n",
    "    divYears = driver.find_elements_by_css_selector(\".dp1 span.cell.year\")\n",
    "    divYears[initYear-2020].click()\n",
    "\n",
    "    # Picker per seleccionar mes\n",
    "    divMonths = driver.find_elements_by_css_selector(\".dp1 span.cell.month\")\n",
    "    divMonths[initMonth-1].click()\n",
    "\n",
    "    # Picker per seleccionar dia\n",
    "    divDays = driver.find_elements_by_css_selector(\".dp1 span.cell.day\")\n",
    "    # Get the days from the previous month in the current mont first week\n",
    "    divBlankDays = driver.find_elements_by_css_selector(\".dp1 span.cell.day.blank\")\n",
    "    divDays[initDay+len(divBlankDays)-1].click()  \n",
    "\n",
    "    # Select end date\n",
    "    endYear=period[1].year\n",
    "    endMonth=period[1].month\n",
    "    endDay=period[1].day\n",
    "\n",
    "    # Picker de la data d'inici\n",
    "    dpkStartdate = driver.find_element_by_css_selector(\"div.vdp-datepicker.dp2\")\n",
    "    dpkStartdate.click()\n",
    "\n",
    "    # Picker per mostrar anys\n",
    "    spnMonthSelector = driver.find_element_by_css_selector(\".dp2 span.day__month_btn.up\")\n",
    "    spnMonthSelector.click()\n",
    "\n",
    "    # Picker per mostrar anys\n",
    "    spnYearSelector = driver.find_element_by_css_selector(\".dp2 span.month__year_btn.up\")\n",
    "    spnYearSelector.click()\n",
    "\n",
    "    # Picker per seleccionar any\n",
    "    divYears = driver.find_elements_by_css_selector(\".dp2 span.cell.year\")\n",
    "    divYears[endYear-2020].click()\n",
    "\n",
    "    # Picker per seleccionar mes\n",
    "    divMonths = driver.find_elements_by_css_selector(\".dp2 span.cell.month\")\n",
    "    divMonths[endMonth-1].click()\n",
    "\n",
    "    # Picker per seleccionar dia\n",
    "    divDays = driver.find_elements_by_css_selector(\".dp2 span.cell.day\")\n",
    "    # Get the days from the previous month in the current mont first week\n",
    "    divBlankDays = driver.find_elements_by_css_selector(\".dp2 span.cell.day.blank\")\n",
    "    divDays[endDay+len(divBlankDays)-1].click()\n",
    "\n",
    "    # Wait for page load\n",
    "    time.sleep(5)  \n",
    "\n",
    "    # Get the number of total races for the given subperiod\n",
    "    logging.info(\"Thread %s: Retrieving number of races\",n) \n",
    "    totalRacesText = re.findall(r'(?<=<h1 class=\"itra-green text-center\">)([0-9]+)(?=.*</h1>)', driver.page_source)\n",
    "    totalRaces = int(totalRacesText[0])\n",
    "    logging.info(\"Thread %s: Number of races %s\",n,totalRaces)    \n",
    "\n",
    "    # Initialize result\n",
    "    resultPeriod = []\n",
    "\n",
    "    if totalRaces > 0:\n",
    "\n",
    "        # Click on More Races to get the full list on the screen & Wait for Visibility of Races until we list all races\n",
    "        maxIterations = int(totalRaces / 50)\n",
    "\n",
    "        logging.info(\"Thread %s: We will use %s iterations for %s races\",n,maxIterations,totalRaces)    \n",
    "\n",
    "        if totalRaces % 50 > 0:\n",
    "            maxIterations = maxIterations + 1\n",
    "\n",
    "        i = 0\n",
    "        try:\n",
    "            logging.info(\"Thread %s for %s period: %s iteration\", period, n, i)\n",
    "            btnSeeMore = driver.find_element_by_css_selector('button.btn-itra-black[type=\"button\"]')    \n",
    "\n",
    "        except:\n",
    "            btnSeeMore = None\n",
    "            logging.info(\"Thread %s for %s period: No more races\", period, n)\n",
    "\n",
    "        while btnSeeMore is not None and i != maxIterations-1:\n",
    "            i = i+1        \n",
    "\n",
    "            try:\n",
    "                btnSeeMore.click()\n",
    "                logging.info(\"Thread %s for %s period: %s iteration\", period, n, i)\n",
    "                btnSeeMore = driver.find_element_by_css_selector('button.btn-itra-black[type=\"button\"]') \n",
    "                \n",
    "            except:            \n",
    "                btnSeeMore = None\n",
    "                logging.info(\"Thread %s for %s period: No more races\", period, n)\n",
    "                break\n",
    "\n",
    "            finally:\n",
    "                time.sleep(5)\n",
    "        \n",
    "        # Obtnim les dades amb BaeatifulSoup \n",
    "        resultPeriod = getData(n, driver.page_source)\n",
    "        logging.info(\"Thread %s for %s period: Data frame returned with %s records\", period, n, len(resultPeriod))\n",
    "    else:\n",
    "        #Generate a dataframe empty with the same structure\n",
    "        list_of_tuples = list(zip([], [], [], [], [], [])) \n",
    "        resultPeriod = pd.DataFrame(list_of_tuples, columns = ['Name', 'Link', 'Distance', 'Gain', 'Loss', 'Date'])\n",
    "    driver.quit()\n",
    "    return resultPeriod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definim una funció que obten les curses limitant el número de dies del periode a consultar. En cas que hi hagi més dies executa el procés de forma iterativa per evitar problemes de rendiment i estabilitat en execucions massa llargues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRacesSeq(n, period, maxDuration=30):\n",
    "    \"\"\"\n",
    "    getRacesSeq gets the races from ITRA in the given period time. Opens a new browser session for each maxDuration days to avoid issues with the borwser when too much races needs to bre retrieved.\n",
    "\n",
    "    :param n: Thread context execution\n",
    "    :param period: Start and End date \n",
    "    :param maxDuration: Maximum days to query to the browser\n",
    "    :return: All races with high level data for the given period\n",
    "    \"\"\" \n",
    "    logging.info(\"Thread %s for %s period: starting getRacesSeq\", n, period)\n",
    "\n",
    "    # Get the number of subperiods\n",
    "    duration = period[1] - period[0]\n",
    "    durationDays = int(duration.total_seconds() / 60 / 60 / 24)\n",
    "    \n",
    "    logging.info(\"Thread %s for %s period: Period duration is %s days\", n, period,durationDays)\n",
    "    subperiodsSeq = splitTimePeriod(int(durationDays/maxDuration), period[0], period[1])\n",
    "    logging.info(\"Thread %s for %s period: Periods %s\", n, period,subperiodsSeq)\n",
    "    \n",
    "    i = 0\n",
    "    result = []\n",
    "\n",
    "    while i < len(subperiodsSeq):\n",
    "        logging.info(\"Thread %s for %s period: Processing period\", n, subperiodsSeq[i])\n",
    "        resultAux = getRaces(n,subperiodsSeq[i])\n",
    "        logging.info(\"Thread %s for %s period: Processed period with %s races\", n, subperiodsSeq[i], len(resultAux))\n",
    "        result.append(resultAux)\n",
    "        i = i + 1\n",
    "    result  = pd.concat(result)\n",
    "    logging.info(\"Thread %s for %s period: terminated getRacesSeq with %s records\", n, period, len(result))\n",
    "    return result"
   ]
  },
  {
   "source": [
    "Amb les funcions anteriors podem fer l'execució on inicialitzem les variables d'entrada."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Period definition\n",
    "startDate = datetime.datetime(2020, 1, 1, 0, 0, 0)\n",
    "endDate = datetime.datetime(2022, 6, 30, 0, 0, 0)\n",
    "\n",
    "# Number of threads\n",
    "threads = 3\n",
    "\n",
    "# Get periods\n",
    "periods = splitTimePeriod(threads, startDate, endDate)\n",
    "\n",
    "# Parallel execution\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=threads) as executor:\n",
    "    resultPeriods = list(executor.map(getRacesSeq, range(threads),periods))\n",
    "\n",
    "# Concatene all results\n",
    "resultFullPeriod = pd.concat(resultPeriods)\n",
    "logging.info(\"Races for period %s to %s is %s\", startDate, endDate, len(resultFullPeriod))\n",
    "print(resultFullPeriod)\n"
   ]
  },
  {
   "source": [
    "Obtenim els identificadors únics de les curses"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary part of the string\n",
    "sep = 'https://itra.run/race/'\n",
    "id_unic =[item.split(sep, 1)[1] for item in resultFullPeriod['Link'].tolist()]\n",
    "\n",
    "# Removing single quotes (effectively transforms it to int)\n",
    "id_unic_int=[int(x) for x in id_unic]\n",
    "\n",
    "# Adding to the dataset\n",
    "resultFullPeriod['id_course'] = id_unic_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ara ataquem les dades de la pàgina específica de cada cursa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Extraccio de dades de les planes detallades\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Removing single quotes (effectively transforms it to int)\n",
    "id_unic_int=[int(x) for x in id_unic]\n",
    "\n",
    "# Remove duplicates\n",
    "id_unic_int=set(id_unic_int)\n",
    "id_unic_int=list(id_unic_int)\n",
    "\n",
    "# List of json containing datailed info on each race\n",
    "jsonList = []\n",
    "\n",
    "# Add year in the dataset as the PK for a race is id and year\n",
    "resultFullPeriod['Year'] = resultFullPeriod['Date'].str[-4:].astype(int)\n",
    "\n",
    "# List of json containing datailed info on each race\n",
    "cursesList = []\n",
    "\n",
    "# Loop over the urls to obtain details in json\n",
    "for item in id_unic_int:\n",
    "    \n",
    "    try:\n",
    "        # Get the years of the course\n",
    "        years = len(resultFullPeriod.loc[resultFullPeriod['id_course'] == item])\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        while i < years:\n",
    "            # get the year of the course\n",
    "            year = (resultFullPeriod.loc[resultFullPeriod['id_course'] == item]).iloc[i]['Year']\n",
    "            \n",
    "            # url and request\n",
    "            url = \"https://itra.run/evt/racewdetails/\"\n",
    "            final_url = f'{url}{item}/{year}'\n",
    "            \n",
    "            logging.info(\"Requesting %s\",final_url)\n",
    "            r = requests.get(final_url, verify=False)\n",
    "            logging.info(\"Requested %s with HTTP status %s\",final_url,r.status_code)\n",
    "            \n",
    "        \n",
    "            # Add to list of json races\n",
    "            cursa=r.json()[0]\n",
    "            jsonList.append(cursa)\n",
    "            \n",
    "            # Add to dataframe of races    \n",
    "            df_cursa = pd.DataFrame([cursa])\n",
    "            cursesList.append(df_cursa)\n",
    "\n",
    "            i = i + 1\n",
    "    except:\n",
    "        logging.error(\"Error processing race with %s (%s)\",final_url,sys.exc_info()[0])\n",
    "\n",
    "\n",
    "# Dataframe detailed race information\n",
    "df_detailed = pd.concat(cursesList)\n",
    "df_detailed=df_detailed.reset_index(drop=True)\n",
    "\n",
    "# Concatenate df & df_detailed by column\n",
    "resultFullPeriod = pd.merge(resultFullPeriod, df_detailed, left_on=['id_course','Year'], right_on=['id_course','annee'])\n",
    "logging.info(\"Processed all %s races in the period %s - %s\", len(resultFullPeriod),startDate,endDate)\n",
    "        "
   ]
  },
  {
   "source": [
    "Eliminem les columnes que no ens interessen i guardem el fitxer en format CSV"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns\n",
    "del resultFullPeriod[\"Gain\"]\n",
    "del resultFullPeriod[\"Loss\"]\n",
    "del resultFullPeriod[\"dt\"]\n",
    "del resultFullPeriod[\"descr\"]\n",
    "del resultFullPeriod[\"descr_en\"]\n",
    "del resultFullPeriod[\"nb_eqp\"]\n",
    "del resultFullPeriod[\"nb_pts_tps\"]\n",
    "del resultFullPeriod[\"type_course\"]\n",
    "del resultFullPeriod[\"inscr_cond\"]\n",
    "del resultFullPeriod[\"brouillon\"]\n",
    "del resultFullPeriod[\"dist_tot2\"]\n",
    "del resultFullPeriod[\"ravitos\"]\n",
    "\n",
    "# Save the file\n",
    "resultFullPeriod.to_csv(\"Trail Running Races 2020-2029.csv\",index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resultFullPeriod.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_detailed.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python392jvsc74a57bd01d8c173c76670bfef6af75343b55d0ce57a70adcaf80f0f51757d96bbb3ee487",
   "display_name": "Python 3.9.2 64-bit ('PRA1002': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}